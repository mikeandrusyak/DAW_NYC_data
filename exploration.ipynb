{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Exploration der Dataset\n",
    "In diesem Notebook werden die ersten Schritte im Data Wrangling gemacht, das explorieren. \n",
    "Da die Datasets aber sehr gross sind, wird DuckDB genutzt, um die Daten erstmal in Memory zu persistieren, \n",
    "damit St√ºck f√ºr St√ºck die Daten eingelesen werden k√∂nnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "import json \n",
    "import tempfile\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Einlesen der Daten in DuckDB\n",
    "\n",
    "**DuckDB** ist eine in-memory Datenbank, welche uns erm√∂glicht einen sehr grossen Datensatz einzulesen und diesen St√ºckweise\n",
    "im Code zu verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen der CSV-Datei und Konvertierung in Parquet\n",
    "con = duckdb.connect(\"mydb.duckdb\")\n",
    "data_sets = [\n",
    "     \"data/medianAskingRent_All.csv\",\n",
    "]\n",
    "\n",
    "selected_columns = [\n",
    "    \"unique_key\",\n",
    "    \"created_date\",\n",
    "    \"closed_date\",\n",
    "    \"agency\",\n",
    "    \"agency_name\",\n",
    "    \"complaint_type\",\n",
    "    \"descriptor\",\n",
    "    \"location_type\",\n",
    "    \"incident_zip\",\n",
    "    \"incident_address\",\n",
    "    \"street_name\",\n",
    "    \"borough\",\n",
    "    \"city\",\n",
    "    \"cross_street_1\",\n",
    "    \"cross_street_2\",\n",
    "    \"intersection_street_1\",\n",
    "    \"intersection_street_2\",\n",
    "    \"address_type\",\n",
    "    \"landmark\",\n",
    "    \"facility_type\",\n",
    "    \"status\",\n",
    "    \"due_date\",\n",
    "    \"resolution_description\",\n",
    "    \"park_borough\",\n",
    "    \"park_facility_name\",\n",
    "    \"resolution_action_updated_date\",\n",
    "    \"community_board\",\n",
    "    \"bbl\",\n",
    "    \"open_data_channel_type\",\n",
    "]\n",
    "\n",
    "def generate_quarters(start_year, end_year):\n",
    "    quarters = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        quarters.append((f\"{year}-01-01T00:00:00\", f\"{year}-03-31T23:59:59\"))\n",
    "        quarters.append((f\"{year}-04-01T00:00:00\", f\"{year}-06-30T23:59:59\"))\n",
    "        quarters.append((f\"{year}-07-01T00:00:00\", f\"{year}-09-30T23:59:59\"))\n",
    "        quarters.append((f\"{year}-10-01T00:00:00\", f\"{year}-12-31T23:59:59\"))\n",
    "    return quarters\n",
    "\n",
    "for csv_file in data_sets:\n",
    "    # Filename f√ºr Parquet bestimmen und Tabelle benennen \n",
    "    parquet_file = csv_file.replace(\".csv\", \".parquet\")\n",
    "    table_name = csv_file.split(\"/\")[-1].replace(\".csv\", \"\").replace(\"-\", \"_\")\n",
    "    # Tabellenname darf nicht mit Zahl beginnen\n",
    "    if re.match(r'^\\d', table_name):\n",
    "        table_name = \"t_\" + table_name\n",
    "\n",
    "    print(f\"Tablename: {table_name}\")\n",
    "    try:\n",
    "        con.execute(f\"\"\"\n",
    "            COPY (SELECT * FROM read_csv_auto('{csv_file}'))\n",
    "            TO '{parquet_file}' (FORMAT 'parquet');\n",
    "        \"\"\")\n",
    "        print(f\"Conversion successfull {csv_file} ‚Üí {parquet_file}\")\n",
    "        print(\"--------------------------------\")\n",
    "        con.execute(f\"\"\"\n",
    "            CREATE OR REPLACE TABLE {table_name} AS\n",
    "            SELECT * FROM read_parquet('{parquet_file}');\n",
    "        \"\"\")\n",
    "        print(f\"{csv_file} Table successfully converted!\")\n",
    "        print(\"--------------------------------\")\n",
    "        print(\"--------------------------------\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Failed to convert:\", e)\n",
    "\n",
    "print(\"CSV successfully converted to parquet and Table created!\")\n",
    "\n",
    "# Generates quarters from 2021 to 2025\n",
    "quarters = generate_quarters(2024, 2025)\n",
    "\n",
    "# Fetch data from Socrata API and create table\n",
    "client = Socrata(\"data.cityofnewyork.us\",\n",
    "                  \"Upkc825Y13IyAEMlWSq4kL2dz\",\n",
    "                  username=\"roberto.fazekas.priv@gmail.com\",\n",
    "                  password=\"jugGom-kypcom-pytsu3\",\n",
    "                  timeout=120)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 50_000\n",
    "table_created = False\n",
    "table_cols = None  # merken, welche Spalten die Tabelle hat\n",
    "\n",
    "# --- Quartale laden ---\n",
    "for start, end in quarters:\n",
    "    print(f\"\\nüì• Lade Daten von {start} bis {end}\")\n",
    "\n",
    "    offset = 0\n",
    "    total_rows = 0\n",
    "    batch_idx = 0\n",
    "\n",
    "    while True:\n",
    "        results = client.get(\n",
    "            \"erm2-nwe9\",\n",
    "            select= \",\".join(selected_columns),\n",
    "            where=f\"created_date between '{start}' and '{end}'\",\n",
    "            limit=BATCH_SIZE,\n",
    "            offset=offset,\n",
    "        )\n",
    "\n",
    "        if not results:\n",
    "            break\n",
    "        \"\"\"\n",
    "        # In DataFrame wandeln (nur f√ºr Typ-Cleaning)\n",
    "        df = pd.DataFrame.from_records(results)\n",
    "\n",
    "        # alle object-Spalten in String casten (gegen STRUCT-Mischtypen)\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == \"object\":\n",
    "                df[col] = df[col].astype(str)\n",
    "\n",
    "        # wieder als JSON-String speichern\n",
    "        json_str = df.to_json(orient=\"records\")\n",
    "        \"\"\"\n",
    "        json_str = json.dumps(results)\n",
    "\n",
    "\n",
    "        # Tmp-Datei nutzen (automatisch gel√∂scht, wenn geschlossen)\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".json\") as tmp:\n",
    "            tmp.write(json_str.encode(\"utf-8\"))\n",
    "            tmp.flush()  # sicherstellen, dass geschrieben wurde\n",
    "\n",
    "            # Tabelle beim ersten Batch erzeugen\n",
    "            if not table_created:\n",
    "                con.execute(f\"\"\"\n",
    "                    CREATE OR REPLACE TABLE calls_311 AS \n",
    "                    SELECT * FROM read_json_auto('{tmp.name}') \n",
    "                \"\"\")\n",
    "                table_created = True\n",
    "                print(\"üÜï Tabelle calls_311 erstellt (Schema vom ersten Batch)\")\n",
    "\n",
    "            # Insert direkt aus JSON-Tempfile\n",
    "            con.execute(f\"\"\"\n",
    "                INSERT INTO calls_311 \n",
    "                SELECT * FROM read_json_auto('{tmp.name}')\n",
    "            \"\"\")\n",
    "\n",
    "        rows = len(results)\n",
    "        total_rows += rows\n",
    "        print(f\"   ‚û°Ô∏è Batch {batch_idx} mit {rows} Zeilen gespeichert (Offset={offset})\")\n",
    "\n",
    "        offset += BATCH_SIZE\n",
    "        batch_idx += 1\n",
    "\n",
    "    print(f\"‚úÖ Quartal {start[:7]} bis {end[:7]} geladen, insgesamt {total_rows} Zeilen.\")\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufbau der Verbindung zur DuckDB-Datenbank\n",
    "con = duckdb.connect(\"mydb.duckdb\")\n",
    "\n",
    "df_affordable = con.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM medianAskingRent_All\n",
    "    LIMIT 100\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "res = con.execute(\"SELECT COUNT(*) FROM calls_311\").fetchone()[0]\n",
    "print(\"Anzahl Zeilen:\", res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python daw .venv",
   "language": "python",
   "name": "myproj-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
