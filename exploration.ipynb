{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Exploration der Dataset\n",
    "In diesem Notebook werden die ersten Schritte im Data Wrangling gemacht, das explorieren. \n",
    "Da die Datasets aber sehr gross sind, wird DuckDB genutzt, um die Daten erstmal in Memory zu persistieren, \n",
    "damit Stück für Stück die Daten eingelesen werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Einlesen der Daten in DuckDB\n",
    "\n",
    "**DuckDB** ist eine in-memory Datenbank, welche uns ermöglicht einen sehr grossen Datensatz einzulesen und diesen Stückweise\n",
    "im Code zu verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen der CSV-Datei und Konvertierung in Parquet\n",
    "con = duckdb.connect(\"mydb.duckdb\")\n",
    "data_sets = [\n",
    "     \"data/311-service-requests-from-2010-to-present.csv\",\n",
    "     \"data/affordable_housing.csv\",\n",
    "]\n",
    "\n",
    "for csv_file in data_sets:\n",
    "    # Filename für Parquet bestimmen und Tabelle benennen \n",
    "    parquet_file = csv_file.replace(\".csv\", \".parquet\")\n",
    "    table_name = csv_file.split(\"/\")[-1].replace(\".csv\", \"\").replace(\"-\", \"_\")\n",
    "    # Tabellenname darf nicht mit Zahl beginnen\n",
    "    if re.match(r'^\\d', table_name):\n",
    "        table_name = \"t_\" + table_name\n",
    "\n",
    "    print(f\"Tablename: {table_name}\")\n",
    "    try:\n",
    "        con.execute(f\"\"\"\n",
    "            COPY (SELECT * FROM read_csv_auto('{csv_file}'))\n",
    "            TO '{parquet_file}' (FORMAT 'parquet');\n",
    "        \"\"\")\n",
    "        print(f\"✅ {csv_file} → {parquet_file}\")\n",
    "        print(\"--------------------------------\")\n",
    "        con.execute(f\"\"\"\n",
    "            CREATE OR REPLACE TABLE {table_name} AS\n",
    "            SELECT * FROM read_parquet('{parquet_file}');\n",
    "        \"\"\")\n",
    "        print(f\"✅ {csv_file} erfolgreich konvertiert!\")\n",
    "        print(\"--------------------------------\")\n",
    "        print(\"--------------------------------\")\n",
    "    except Exception as e:\n",
    "        print(\"❌ Fehler bei der Konvertierung:\", e)\n",
    "\n",
    "print(\"✅ CSV erfolgreich nach Parquet konvertiert!\")\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufbau der Verbindung zur DuckDB-Datenbank\n",
    "con = duckdb.connect(\"mydb.duckdb\")\n",
    "\n",
    "# 5 Zeilen aus CSV\n",
    "df_311 = con.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM t_311_service_requests_from_2010_to_present\n",
    "    WHERE \"Closed Date\" IS NOT NULL\n",
    "    LIMIT 10\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "df_affordable = con.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM affordable_housing\n",
    "    LIMIT 10\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "df_affordable.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python daw .venv",
   "language": "python",
   "name": "myproj-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
